{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 載入套件與資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Layers for FNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# Layers for CNN\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "# For data preprocessing\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fashion MNIST dataset\n",
    "(x_train, y_train0), (x_test, y_test0) = datasets.fashion_mnist.load_data()\n",
    "\n",
    "# standardized\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_categorical(y_train0, 10)\n",
    "y_test = to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 7777\n",
    "plt.imshow(x_train[n])\n",
    "plt.title(class_names[y_train0[n].squeeze()])\n",
    "plt.axis(\"off\");\n",
    "print(x_train[n].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做reshape\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 建立用於分類Fashion MNIST的卷積神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layers = [Conv2D(32, (3, 3), input_shape=(28, 28, 1), padding=\"same\", activation=\"relu\", name=\"Conv_1\"),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", name='Conv_3'),\n",
    "              GlobalAveragePooling2D()]\n",
    "\n",
    "FC_layers = [Dense(units=100, activation=\"relu\"),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fashion = Sequential(CNN_layers + FC_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 106,582\n",
      "Trainable params: 106,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fashion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fashion.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 29s 483us/sample - loss: 0.8356 - accuracy: 0.6898 - val_loss: 0.6177 - val_accuracy: 0.7620\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 34s 566us/sample - loss: 0.5533 - accuracy: 0.7954 - val_loss: 0.5261 - val_accuracy: 0.8113\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 37s 610us/sample - loss: 0.4766 - accuracy: 0.8273 - val_loss: 0.4889 - val_accuracy: 0.8216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15c3c2c50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fashion.fit(x_train, y_train, batch_size=64, epochs=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.4567 - accuracy: 0.8308\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.4889 - accuracy: 0.8216\n",
      "Train Accuracy: 83.08166861534119\n",
      "Test Accuracy: 82.16000199317932\n"
     ]
    }
   ],
   "source": [
    "# 預測資料集的準確率\n",
    "score_train = model_fashion.evaluate(x_train, y_train)\n",
    "score_test = model_fashion.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 利用Transfer Learning的Layer Transfer借上面model的CNN層來訓練分類MNIST資料的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = range(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀MNIST\n",
    "(u_train, v_train0), (u_test, v_test0) = datasets.mnist.load_data()\n",
    "\n",
    "# standardized\n",
    "u_train = u_train / u_train.max()\n",
    "u_test = u_test / u_test.max()\n",
    "\n",
    "# One-hot encoding\n",
    "v_train = to_categorical(v_train0, 10)\n",
    "v_test = to_categorical(v_test0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 7777\n",
    "plt.imshow(u_train[n])\n",
    "plt.title(y_list[v_train0[n].squeeze()])\n",
    "plt.axis(\"off\");\n",
    "print(u_train[n].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "u_train = u_train.reshape(60000, 28, 28, 1)\n",
    "u_test = u_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_layers_mnist = [Dense(units=50, activation='relu'),\n",
    "                   Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 99,632\n",
      "Trainable params: 99,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_mnist = Sequential(CNN_layers+FC_layers_mnist)\n",
    "model_mnist.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN_layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 99,632\n",
      "Trainable params: 6,960\n",
      "Non-trainable params: 92,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_mnist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.9158 - accuracy: 0.7366 - val_loss: 0.4444 - val_accuracy: 0.8768\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 8s 136us/sample - loss: 0.3960 - accuracy: 0.8855 - val_loss: 0.3222 - val_accuracy: 0.8994\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 8s 136us/sample - loss: 0.3191 - accuracy: 0.9029 - val_loss: 0.2860 - val_accuracy: 0.9113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ca0e1d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mnist.compile(loss='categorical_crossentropy', \n",
    "                    optimizer=Adam(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "model_mnist.fit(u_train, v_train,\n",
    "                batch_size=64, \n",
    "                epochs=3,\n",
    "                validation_data=(u_test, v_test)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 由上述訓練過程中，可以發現跟已經訓練好的模型借CNN層之後，訓練的效果也很好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
